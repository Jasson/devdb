1. Dynamo的NWR模型:

Dynamo要考虑一个问题, 各个节点间数据备份是同步还是异步. 假设我们要求写请求总是尽可能的成功, 那么我们的策略是写任何一个节点
成功就认为成功.节点之间的数据通过异步形式达成一致, 这个时候读请求可能读不到最新写进去的信息.

比如我们一个数据在A B C 三个节点各存一份(系统中有三个备份的时候, 下面的讨论都是基于这个假设的), 那么当写A成功后, 另外一个进程
从节点C读数据,这个时候C还没收到最新的数据, 只能给读请求一个较老的版本, 这个可能会带来大问题; 同样,如果我们希望读请求总能读到正
确的数据, 那我们的策略是写的时候要等A B C三个节点都写成功了才认为写成功. 这个时候写请求可能要耗较多的时间, 甚至根本不能完成(如
果有节点不可达)也就是说, 系统的一致性, 可靠性, 原子性, 隔离性的问题(ACID)是无法同时达到的. 只能在其中做出取舍.

Dynamo的处理方式是把这个选择权交给用户, 这就是它的N W R模型. N代表N个备份, W代表要写入至少W份才认为成功, R表示至少读取R个
备份, 配置的时候要求W+R > N. 因为W+R > N, 所以 R > N-W这个是什么意思呢?
就是读取的份数一定要比总备份数减去确保写成功的倍数的差值要大. 也就是说, 每次读取, 都至少读取到一个最新的版本. 从而不会读到一份
旧数据. 当我们需要高可写的环境的时候(例如: amazon的购物车的添加请求应该是永远不被拒绝的)我们可以配置W = 1 如果N=3 那么R = 3. 
这个时候只要写任何节点成功就认为成功,但是读的时候必须从所有的节点都读出数据. 如果我们要求读的高效率, 我们可以配置 W=N R=1. 
这个时候任何一个节点读成功就认为成功, 但是写的时候必须写所有三个节点成功才认为成功.

大家注意, 一个操作的耗时是几个并行操作中最慢一个的耗时. 比如R=3的时候, 实际上是向三个节点同时发了读请求, 要三个节点都返回结果
才能认为成功. 假设某个节点的响应很慢, 它就会严重拖累一个读操作的响应速度.

2. 解决数据版本问题
这里我们需要讨论一下数据版本问题, 这个问题不仅仅存在于分布式系统, 只是分布式系统的一些要求使得这个问题更复杂.
先看个简单的例子:
用户x对key1做了一次写入操作, 我们设值是数字3. 然后用户y读取了key1, 这个时候用户y知道的值是3. 然后用户x对值做了一个+1操作,
将新值写入, 现在key1的值是4了. 而用户y也做了一次+1操作, 然后写入, 因为用户y读到的值是3, y不知道这个值现在已经变化了, 结果
按照语义本应该是5的值, 现在还是4.

解决这个问题常用的方法是设置一个版本值, 用户x第一次写入key1 值3的时候, 产生一个版本设为v1, 用户y读取的信息中包括版本编号v1, 
当x做了加1把值4写入的时候, 告诉server自己拿到的是版本v1, 要在v1的基础上把值改成4. server发现自己保存的版本的确是v1所以就
同意这个写入, 并且把版本改成v2. 这个时候y也要写入4, 并且宣称自己是在版本v1上做的修改,但是因为server发现自己手里已经是版本v2了,
所以server就拒绝y的写入请求, 告诉y, 版本错误. 这个算法在版本冲突的时候经常被使用. 但是刚才我们描述的分布式系统不能简单采用这个方式来实现.

假设我们设置了N=3 W=1, 现在x写入key1 值3, 这个请求被节点A处理, 生成了v1版本的数据. 然后x用户又在版本v1上进行了一次key1值4的写操作,
这个请求这次是节点C处理的. 但是节点C还没有收到上一个A接收的版本(数据备份是异步进行的)如果按照上面的算法, 他应该拒绝这个请求, 因为他不了
解版本v1的信息. 但是实际上是不可以拒绝的, 因为如果C拒绝了写请求, 实际上W=1这个配置, 这个服务器向客户做出的承诺将被打破, 从而使得系统的
行为退化成W=N的形式. 那么C接收了这个请求, 就可能产生前面提到的不一致性.如何解决这个问题呢?
Dynamo的方法是保留所有这些版本, 用vector clock记录版本信息. 当读取操作发生的时候返回多个版本, 由客户端的业务层来解决这个冲突合并各个
版本. 当然客户端也可以选择最简单的策略, 就是最近一次的写覆盖以前的写.

3. vector clock算法保证版本信息
这里又引入了一个vector clock算法, 这里简单介绍一下, 可以把这个vector clock想象成每个节点都记录自己的版本信息, 而一个数据, 包含所有这些版本
信息.
来看一个例子： 假设一个写请求, 第一次被节点A处理了, 节点A会增加一个版本信息(A.1), 我们把这个时候的数据记做D1(A.1). 然后另外一个对同样key(这一
段讨论都是针对同样的key的)的请求还是被A处理了于是有D2(A.2).

这个时候, D2是可以覆盖D1的, 不会有冲突产生. 现在我们假设D2传播到了所有节点(B和C), B和C收到的数据不是从客户产生的, 而是别人复制给他们的, 所以他们
不产生新的版本信息, 所以现在B和C都持有数据D2(A.2). 好, 继续, 又一个请求, 被B处理了, 生成数据D3(A.2;B.1), 因为这是一个新版本的数据, 被B处理,
所以要增加B的版本信息.

假设D3没有传播到C的时候又一个请求被C处理记做D4(A.2;C.1), 假设在这些版本没有传播开来以前, 有一个读取操作, 我们要记得, 我们的W=1 那么R=N=3, 所以
R会从所有三个节点上读, 在这个例子中将读到三个版本, A上的D2(A.2);B上的D3(A.2;B.1);C上的D4(A.2;C.1)这个时候可以判断出, D2已经是旧版本, 可以舍弃,
但是D3和D4都是新版本.需要应用自己去合并.

如果需要高可写性, 就要处理这种合并问题, 好假设应用完成了冲突解决, 这里就是合并D3和D4版本, 然后重新做了写入, 假设是B处理这个请求, 于是有D5(A.2;B.2;C.1);
这个版本将可以覆盖掉D1-D4那四个版本. 这个例子只举了一个客户的请求在被不同节点处理时候的情况, 而且每次写更新都是可接受的.

上面问题看似好像可以通过在三个节点里选择一个主节点来解决, 所有的读取和写入都从主节点来进行. 但是这样就违背了W=1这个约定, 实际上还是退化到W=N的情况了. 所以如
果系统不需要很大的弹性, W=N为所有应用都接受, 那么系统的设计上可以得到很大的简化.
Dynamo为了给出充分的弹性而被设计成完全的对等集群(peer to peer), 网络中的任何一个节点都不是特殊的.

　
